{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "\n",
    "# Read in the training CSV file\n",
    "print(\"Reading Training csv file.\")\n",
    "df1 = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "df1.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df=df1\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto\"].astype('category')\n",
    "obj_df[\"service\"] = obj_df[\"service\"].astype('category')\n",
    "obj_df[\"state\"] = obj_df[\"state\"].astype('category')\n",
    "obj_df[\"proto_cat\"] = obj_df[\"proto\"].cat.codes\n",
    "obj_df[\"service_cat\"] = obj_df[\"service\"].cat.codes\n",
    "obj_df[\"state_cat\"] = obj_df[\"state\"].cat.codes\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto_cat\"]\n",
    "obj_df[\"service\"] = obj_df[\"service_cat\"]\n",
    "obj_df[\"state\"] = obj_df[\"state_cat\"]\n",
    "\n",
    "obj_df.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_train_all_attacks = obj_df[\"attack_cat\"]\n",
    "obj_df=pd.get_dummies(obj_df, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_train = obj_df.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i,j] = round(X_train[i,j]/maximum,3)\n",
    "\n",
    "# Read in the testing CSV file \n",
    "print(\"Reading Testing csv file.\")\n",
    "df2 = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "df2.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df2=df2\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto\"].astype('category')\n",
    "obj_df2[\"service\"] = obj_df2[\"service\"].astype('category')\n",
    "obj_df2[\"state\"] = obj_df2[\"state\"].astype('category')\n",
    "obj_df2[\"proto_cat\"] = obj_df2[\"proto\"].cat.codes\n",
    "obj_df2[\"service_cat\"] = obj_df2[\"service\"].cat.codes\n",
    "obj_df2[\"state_cat\"] = obj_df2[\"state\"].cat.codes\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto_cat\"]\n",
    "obj_df2[\"service\"] = obj_df2[\"service_cat\"]\n",
    "obj_df2[\"state\"] = obj_df2[\"state_cat\"]\n",
    "\n",
    "obj_df2.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_test_all_attacks = obj_df2[\"attack_cat\"]\n",
    "obj_df2=pd.get_dummies(obj_df2, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_test = obj_df2.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i,j] = round(X_test[i,j]/maximum,3)\n",
    "\n",
    "\n",
    "estimators_number = list(range(10,30))\n",
    "\n",
    "dataspace = 0;\n",
    "overall_accuracy_matrix = [None]*len(X_train)\n",
    "iTERATION=0\n",
    "dataspace_number=1\n",
    "attack_type = 4\n",
    "Y_train = obj_df.values[:,-attack_type]\n",
    "Y_test = obj_df2.values[:,-attack_type]\n",
    "\n",
    "cleanup_nums = {\"Worms\":0, \"Shellcode\":1, \"Reconnaissance\":2, \"Normal\":3, \"Generic\":4, \"Fuzzers\":5, \"Exploits\":6, \"DoS\":7, \"Backdoor\":8, \"Analysis\":9}\n",
    "Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "Y_test_all_attacks.replace(cleanup_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['maximum', 'pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "os.chdir('/root/pathint/fig_split_mnist')\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 43\n",
    "output_dim = 10\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 43\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[7,9],[3,8],[0,6],[4,2]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 10\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_train[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_train[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0, 422x43 matrix: ID_MLE = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:143: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1, 40496x43 matrix: ID_MLE = 5\n",
      "Task 2, 24933x43 matrix: ID_MLE = 2\n",
      "Task 3, 15221x43 matrix: ID_MLE = 4\n",
      "Task 4, 1260x43 matrix: ID_MLE = 2\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/OFAI/hub-toolbox-python3/blob/master/hub_toolbox/IntrinsicDim.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This file is part of the HUB TOOLBOX available at\n",
    "http://ofai.at/research/impml/projects/hubology.html\n",
    "Source code is available at\n",
    "https://github.com/OFAI/hub-toolbox-python3/\n",
    "The HUB TOOLBOX is licensed under the terms of the GNU GPLv3.\n",
    "(c) 2011-2016, Dominik Schnitzer and Roman Feldbauer\n",
    "Austrian Research Institute for Artificial Intelligence (OFAI)\n",
    "Contact: <roman.feldbauer@ofai.at>\n",
    "This file is based on a Matlab script by Elizaveta Levina, University of \n",
    "Michigan, available at http://dept.stat.lsa.umich.edu/~elevina/mledim.m\n",
    "Reference:  E. Levina and P.J. Bickel (2005).  \n",
    " \"Maximum Likelihood Estimation  of Intrinsic Dimension.\"  \n",
    " In Advances in NIPS 17, Eds. L. K. Saul, Y. Weiss, L. Bottou. \n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def intrinsic_dimension(X:np.ndarray, k1:int=6, k2:int=12, \n",
    "                        estimator:str='levina', metric:str='vector', \n",
    "                        trafo:str='var', mem_threshold:int=5000):\n",
    "    \"\"\"Calculate intrinsic dimension based on the MLE by Levina and Bickel [1]_.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        - An ``m x n`` vector data matrix with ``n`` objects in an \n",
    "          ``m`` dimensional feature space \n",
    "        - An ``n x n`` distance matrix.\n",
    "        \n",
    "        NOTE: The type must be defined via parameter `metric`!\n",
    "        \n",
    "    k1 : int, optional (default: 6)\n",
    "        Start of neighborhood range to search in.\n",
    "        \n",
    "    k2 : int, optional (default: 12)\n",
    "        End of neighborhood range to search in.\n",
    "        \n",
    "    estimator : {'levina', 'mackay'}, optional (default: 'levina')\n",
    "        Determine the summation strategy: see [2]_.\n",
    "    \n",
    "    metric : {'vector', 'distance'}, optional (default: 'vector')\n",
    "        Determine data type of `X`. \n",
    "        \n",
    "        NOTE: the MLE was derived for euclidean distances. Using \n",
    "        other dissimilarity measures may lead to undefined results.\n",
    "        \n",
    "    trafo : {None, 'std', 'var'}, optional (default: 'var')\n",
    "        Transform vector data. \n",
    "        \n",
    "        - None: no transformation\n",
    "        - 'std': standardization \n",
    "        - 'var': subtract mean, divide by variance (default behavior of \n",
    "          Laurens van der Maaten's DR toolbox; most likely for other \n",
    "          ID/DR techniques).\n",
    "    mem_treshold : int, optional, default: 5000\n",
    "        Controls speed-memory usage trade-off: If number of points is higher\n",
    "        than the given value, don't calculate complete distance matrix at\n",
    "        once (fast, high memory), but per row (slower, less memory).\n",
    "    Returns\n",
    "    -------\n",
    "    d_mle : int\n",
    "        Intrinsic dimension estimate (rounded to next integer)\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Levina, E., & Bickel, P. (2004). Maximum likelihood estimation of \n",
    "           intrinsic dimension. Advances in Neural Information …, 17, 777–784. \n",
    "           http://doi.org/10.2307/2335172\n",
    "    .. [2] http://www.inference.phy.cam.ac.uk/mackay/dimension/\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    if estimator not in ['levina', 'mackay']:\n",
    "        raise ValueError(\"Parameter 'estimator' must be 'levina' or 'mackay'.\")\n",
    "    if k1 < 1 or k2 < k1 or k2 >= n:\n",
    "        raise ValueError(\"Invalid neighborhood: Please make sure that \"\n",
    "                         \"0 < k1 <= k2 < n. (Got k1={} and k2={}).\".\n",
    "                         format(k1, k2))\n",
    "    X = X.copy().astype(float)\n",
    "        \n",
    "    if metric == 'vector':\n",
    "        # New array with unique rows   \n",
    "        X = X[np.lexsort(np.fliplr(X).T)]\n",
    "        \n",
    "        if trafo is None:\n",
    "            pass\n",
    "        elif trafo == 'var':\n",
    "            X -= X.mean(axis=0) # broadcast\n",
    "            X /= X.var(axis=0) + 1e-7 # broadcast\n",
    "        elif trafo == 'std':\n",
    "            # Standardization\n",
    "            X -= X.mean(axis=0) # broadcast\n",
    "            X /= X.std(axis=0) + 1e-7 # broadcast\n",
    "        else:\n",
    "            raise ValueError(\"Transformation must be None, 'std', or 'var'.\")\n",
    "        \n",
    "        # Compute matrix of log nearest neighbor distances\n",
    "        X2 = (X**2).sum(1)\n",
    "        \n",
    "        \n",
    "        distance = X2.reshape(-1, 1) + X2 - 2*np.dot(X, X.T) #2x br.cast\n",
    "        distance.sort(1)\n",
    "        # Replace invalid values with a small number\n",
    "        distance[distance<=0] = 1e-7\n",
    "        \n",
    "        try:\n",
    "            knnmatrix = .5 * np.log(distance[:, 1:k2+1])\n",
    "        except:\n",
    "            print('log caluclation error')\n",
    "        \n",
    "    \n",
    "    elif metric == 'distance':\n",
    "        raise NotImplementedError(\"ID currently only supports vector data.\")\n",
    "        #=======================================================================\n",
    "        # # TODO calculation WRONG\n",
    "        # X.sort(1)\n",
    "        # X[X < 0] = 1e-7\n",
    "        # knnmatrix = np.log(X[:, 1:k2+1])\n",
    "        #=======================================================================\n",
    "    elif metric == 'similarity':\n",
    "        raise NotImplementedError(\"ID currently only supports vector data.\")\n",
    "        #=======================================================================\n",
    "        # # TODO calculation WRONG\n",
    "        # print(\"WARNING: using similarity data may return \"\n",
    "        #       \"undefined results.\", file=sys.stderr)\n",
    "        # X[X < 0] = 0\n",
    "        # distance = 1 - (X / X.max())\n",
    "        # knnmatrix = np.log(distance[:, 1:k2+1])\n",
    "        #=======================================================================\n",
    "    else:\n",
    "        raise ValueError(\"Parameter 'metric' must be 'vector' or 'distance'.\")\n",
    "    \n",
    "    # Compute the ML estimate\n",
    "    S = np.cumsum(knnmatrix, 1)\n",
    "    indexk = np.arange(k1, k2+1) # broadcasted afterwards\n",
    "    try:\n",
    "        dividor = S[:, k1-1:k2] - knnmatrix[:, k1-1:k2] * indexk\n",
    "        dhat = -(indexk - 2) / dividor\n",
    "        dhat[dhat < -n] = 0\n",
    "        dhat[dhat > n] = 0\n",
    "    except:\n",
    "        print('dhat calculation error')\n",
    "    \n",
    "    if estimator == 'levina':  \n",
    "        # Average over estimates and over values of k\n",
    "        no_dims = dhat.mean()\n",
    "    if estimator == 'mackay':\n",
    "        # Average over inverses\n",
    "        dhat **= -1\n",
    "        dhat_k = dhat.mean(0)\n",
    "        no_dims = (dhat_k ** -1).mean()       \n",
    "    no_dims = np.nan_to_num(no_dims)\n",
    "    return int(no_dims.round())\n",
    "    \n",
    "\n",
    "class IntrinsicDim(): # pragma: no cover\n",
    "    \"\"\"\n",
    "    .. note:: Deprecated in hub-toolbox 2.3\n",
    "              Class will be removed in hub-toolbox 3.0.\n",
    "              Please use static functions instead.\n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self, X, data_type='vector'):\n",
    "        \"\"\"\n",
    "        .. note:: Deprecated in hub-toolbox 2.3\n",
    "                  Class will be removed in hub-toolbox 3.0.\n",
    "                  Please use static functions instead.\n",
    "        \"\"\"\n",
    "        # Deep copy required due to changes in vector data\n",
    "        self.X = X.copy()\n",
    "        if data_type in ['vector', 'distance', 'similarity']:\n",
    "            self.data_type = data_type\n",
    "            if data_type != 'vector':\n",
    "                raise NotImplementedError(\"IntrinsicDim currently only \"\n",
    "                                          \"supports vector data.\")\n",
    "        else:\n",
    "            raise ValueError(\"Parameter data_type must be 'vector', 'distance'\"\n",
    "                             \" , or 'similarity'. Got '{}' instead.\".\n",
    "                             format(data_type.__str__())) \n",
    "\n",
    "    def calculate_intrinsic_dimensionality(self, k1=6, k2=12, \n",
    "                                           estimator='levina'):\n",
    "        \"\"\"\n",
    "        .. note:: Deprecated in hub-toolbox 2.3\n",
    "                  Class will be removed in hub-toolbox 3.0.\n",
    "                  Please use static functions instead.\n",
    "        \"\"\"\n",
    "        print(\"DEPRECATED: Please use IntrinsicDim.intrinsic_dimension().\", \n",
    "              file=sys.stderr)\n",
    "        return intrinsic_dimension(self.X, k1, k2, estimator, self.data_type)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for i in range(n_tasks):\n",
    "        VECT_DATA = training_datasets[i][0]\n",
    "        m_dim = VECT_DATA.shape[0]\n",
    "        n_dim = VECT_DATA.shape[1]\n",
    "        id_ = intrinsic_dimension(VECT_DATA, trafo=None)\n",
    "        print(\"Task {}, {}x{} matrix: ID_MLE = {}\".format(i,m_dim, n_dim, id_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
